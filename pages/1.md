# Conditional Generation

<p class=text-2xl>Classifier Guided Generation</p>

$
\begin{aligned}
\nabla_{\mathbf{x}_t} \log q(\mathbf{x}_t, y)
&= \nabla_{\mathbf{x}_t} \log q(\mathbf{x}_t) + \nabla_{\mathbf{x}_t} \log q(y \vert \mathbf{x}_t) \\
&\approx - \frac{1}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) + \nabla_{\mathbf{x}_t} \log f_\phi(y \vert \mathbf{x}_t) \\
&= - \frac{1}{\sqrt{1 - \bar{\alpha}_t}} (\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) - \sqrt{1 - \bar{\alpha}_t} \nabla_{\mathbf{x}_t} \log f_\phi(y \vert \mathbf{x}_t))
\end{aligned}
$

<p class=text-2xl>

- Bootstrap generation with additional classifiers.
- Do not use parallel data when training DPM.
- General pre-trained classifiers cannot be used directly.

</p>

---

# Conditional Generation

<p class=text-2xl>Classifier Guided Generation</p>

<p class=text-2xl>

- Bootstrap generation with additional classifiers.
- Do not use parallel data when training DPM.
- General pre-trained classifiers cannot be used directly.

</p>

<img src="/img/cls-guidance.png"/>

---

# Conditional Generation

<p class=text-2xl>Classifier Free Guidances</p>

$
\begin{aligned}
\nabla_{\mathbf{x}_t} \log p(y \vert \mathbf{x}_t)
&= \nabla_{\mathbf{x}_t} \log p(\mathbf{x}_t \vert y) - \nabla_{\mathbf{x}_t} \log p(\mathbf{x}_t) \\
&= - \frac{1}{\sqrt{1 - \bar{\alpha}_t}}\Big( \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, y) - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \Big) \\
\bar{\boldsymbol{\epsilon}}_\theta(\mathbf{x}_t, t, y)
&= \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, y) - \sqrt{1 - \bar{\alpha}_t} \; w \nabla_{\mathbf{x}_t} \log p(y \vert \mathbf{x}_t) \\
&= \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, y) + w \big(\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, y) - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \big) \\
&= (w+1) \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, y) - w \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)
\end{aligned}
$

<p class=text-2xl>

- High quality.
- Parallel data required.

</p>

---

# Conditional Generation

<p class=text-2xl>As Plug-and-Play Priors</p>

<img class="ml-auto mr-auto w-4/5" src="/img/plug-and-play-algo.png"/>

<p class=text-2xl>

- Execute conditional generation with an optimized concept.
- Models trained on data without Gaussian noise can also be used to guide generation.
- The gradient needs to be calculated for the entire generation model.

</p>

---

# Compare

## Advantage

- High flexibility
- Good quality results  
    [Diffusion Models Beat GANs on Image Synthesis](https://papers.nips.cc/paper/2021/hash/49ad23d1ec9fa4bd8d77d02681df5cfa-Abstract.html)
- Stable training

<p v-click>

## Defect

- The sampling time is much longer than VAE, GAN, etc.  
    - ODE sampling  
        e.g. [DDIM](https://arxiv.org/abs/2010.02502), [DPM-Solver++](https://openreview.net/forum?id=4vGwQqviud5), [UniPC](https://arxiv.org/abs/2302.04867)
    - Knowledge Distillation  
        e.g. [Progressive Distillation](https://openreview.net/forum?id=TIdIXIpzhoI), [Consistency Models](https://arxiv.org/abs/2303.01469)  

</p>

---

# Pretrained Model

- Stable Diffusion (Image)
- [AudioLDM](https://arxiv.org/abs/2301.12503) (Audio)
- [GENIE](https://arxiv.org/abs/2212.11685) (Text)

<br/>

# More Control

ControlNet, DDIB, DPM-Encoder, SDEdit, EdiTTS, etc.

<img class="mr-auto ml-auto w-4/5" src="/img/SDEdit.jpg"/>
